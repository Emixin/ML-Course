{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration and Preprocessing\n",
    "\n",
    "The dataset consists of multiple CSV files containing movie metadata, ratings, keywords, and links. The preprocessing steps included:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Loading the datasets using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "movies_metadata = pd.read_csv('E:\\\\Desktop\\\\final project\\\\data\\\\movies_metadata.csv', low_memory=False)\n",
    "keywords = pd.read_csv('E:\\\\Desktop\\\\final project\\\\data\\\\keywords.csv')\n",
    "credits = pd.read_csv('E:\\\\Desktop\\\\final project\\\\data\\\\credits.csv')\n",
    "links = pd.read_csv('E:\\\\Desktop\\\\final project\\\\data\\\\links.csv')\n",
    "links_small = pd.read_csv('E:\\\\Desktop\\\\final project\\\\data\\\\links_small.csv')\n",
    "ratings_small = pd.read_csv('E:\\\\Desktop\\\\final project\\\\data\\\\ratings_small.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Checking the shapes of the datasets to understand their structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movies_metadata shape: (45466, 24)\n",
      "keywords shape: (46419, 2)\n",
      "credits shape: (45476, 3)\n",
      "links shape: (45843, 3)\n",
      "links_small shape: (9125, 3)\n",
      "ratings_small shape: (100004, 4)\n"
     ]
    }
   ],
   "source": [
    "print(f'movies_metadata shape: {movies_metadata.shape}')\n",
    "print(f'keywords shape: {keywords.shape}')\n",
    "print(f'credits shape: {credits.shape}')\n",
    "print(f'links shape: {links.shape}')\n",
    "print(f'links_small shape: {links_small.shape}')\n",
    "print(f'ratings_small shape: {ratings_small.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Identifying and filling missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movies_metadata null values:\n",
      "adult                    0\n",
      "belongs_to_collection    0\n",
      "budget                   0\n",
      "genres                   0\n",
      "homepage                 0\n",
      "id                       0\n",
      "imdb_id                  0\n",
      "original_language        0\n",
      "original_title           0\n",
      "overview                 0\n",
      "popularity               0\n",
      "poster_path              0\n",
      "production_companies     0\n",
      "production_countries     0\n",
      "release_date             0\n",
      "revenue                  0\n",
      "runtime                  0\n",
      "spoken_languages         0\n",
      "status                   0\n",
      "tagline                  0\n",
      "title                    0\n",
      "video                    0\n",
      "vote_average             0\n",
      "vote_count               0\n",
      "dtype: int64\n",
      "keywords null values:\n",
      "id          0\n",
      "keywords    0\n",
      "dtype: int64\n",
      "credits null values:\n",
      "cast    0\n",
      "crew    0\n",
      "id      0\n",
      "dtype: int64\n",
      "links null values:\n",
      "movieId    0\n",
      "imdbId     0\n",
      "tmdbId     0\n",
      "dtype: int64\n",
      "links_small null values:\n",
      "movieId    0\n",
      "imdbId     0\n",
      "tmdbId     0\n",
      "dtype: int64\n",
      "ratings_small null values:\n",
      "userId       0\n",
      "movieId      0\n",
      "rating       0\n",
      "timestamp    0\n",
      "dtype: int64\n",
      "movies_metadata null values:\n",
      "adult                    0\n",
      "belongs_to_collection    0\n",
      "budget                   0\n",
      "genres                   0\n",
      "homepage                 0\n",
      "id                       0\n",
      "imdb_id                  0\n",
      "original_language        0\n",
      "original_title           0\n",
      "overview                 0\n",
      "popularity               0\n",
      "poster_path              0\n",
      "production_companies     0\n",
      "production_countries     0\n",
      "release_date             0\n",
      "revenue                  0\n",
      "runtime                  0\n",
      "spoken_languages         0\n",
      "status                   0\n",
      "tagline                  0\n",
      "title                    0\n",
      "video                    0\n",
      "vote_average             0\n",
      "vote_count               0\n",
      "dtype: int64\n",
      "keywords null values:\n",
      "id          0\n",
      "keywords    0\n",
      "dtype: int64\n",
      "credits null values:\n",
      "cast    0\n",
      "crew    0\n",
      "id      0\n",
      "dtype: int64\n",
      "links null values:\n",
      "movieId    0\n",
      "imdbId     0\n",
      "tmdbId     0\n",
      "dtype: int64\n",
      "links_small null values:\n",
      "movieId    0\n",
      "imdbId     0\n",
      "tmdbId     0\n",
      "dtype: int64\n",
      "ratings_small null values:\n",
      "userId       0\n",
      "movieId      0\n",
      "rating       0\n",
      "timestamp    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Search for missing data\n",
    "print(f'movies_metadata null values:\\n{movies_metadata.isna().sum()}')\n",
    "print(f'keywords null values:\\n{keywords.isna().sum()}')\n",
    "print(f'credits null values:\\n{credits.isna().sum()}')\n",
    "print(f'links null values:\\n{links.isna().sum()}')\n",
    "print(f'links_small null values:\\n{links_small.isna().sum()}')\n",
    "print(f'ratings_small null values:\\n{ratings_small.isna().sum()}')\n",
    "\n",
    "\n",
    "# Handle movies metadata missing values:\n",
    "\n",
    "\n",
    "# For categorical columns, we fill with \"Unknown\" or a placeholder\n",
    "movies_metadata['belongs_to_collection'] = movies_metadata['belongs_to_collection'].fillna('Unknown')\n",
    "movies_metadata['homepage'] = movies_metadata['homepage'].fillna('Unknown')\n",
    "movies_metadata['overview'] = movies_metadata['overview'].fillna('No overview available')\n",
    "movies_metadata['production_companies'] = movies_metadata['production_companies'].fillna('Unknown')\n",
    "movies_metadata['production_countries'] = movies_metadata['production_countries'].fillna('Unknown')\n",
    "movies_metadata['status'] = movies_metadata['status'].fillna('Unknown')\n",
    "movies_metadata['tagline'] = movies_metadata['tagline'].fillna('No tagline available')\n",
    "movies_metadata['title'] = movies_metadata['title'].fillna('Unknown')\n",
    "movies_metadata['video'] = movies_metadata['video'].fillna('Unknown')\n",
    "movies_metadata['original_language'] = movies_metadata['original_language'].fillna('Unknown')\n",
    "movies_metadata['spoken_languages'] = movies_metadata['spoken_languages'].fillna('Unknown')\n",
    "movies_metadata['poster_path'] = movies_metadata['poster_path'].fillna('Unknown')\n",
    "movies_metadata['release_date'] = movies_metadata['release_date'].fillna('Unknown')\n",
    "movies_metadata['original_title'] = movies_metadata['original_title'].fillna('Unknown')\n",
    "movies_metadata['imdb_id'] = movies_metadata['imdb_id'].fillna('Unknown')\n",
    "\n",
    "\n",
    "# Convert budget, revenue columns to numeric values, invalid values will be converted to NaN\n",
    "movies_metadata['budget'] = pd.to_numeric(movies_metadata['budget'], errors='coerce')\n",
    "movies_metadata['revenue'] = pd.to_numeric(movies_metadata['revenue'], errors='coerce')\n",
    "\n",
    "\n",
    "# Fill missing values with the median for numerical columns\n",
    "movies_metadata['budget'] = movies_metadata['budget'].fillna(movies_metadata['budget'].median())\n",
    "movies_metadata['revenue'] = movies_metadata['revenue'].fillna(movies_metadata['revenue'].median())\n",
    "movies_metadata['runtime'] = movies_metadata['runtime'].fillna(movies_metadata['runtime'].median())\n",
    "movies_metadata['vote_average'] = movies_metadata['vote_average'].fillna(movies_metadata['vote_average'].median())\n",
    "movies_metadata['vote_count'] = movies_metadata['vote_count'].fillna(movies_metadata['vote_count'].median())\n",
    "\n",
    "\n",
    "# Convert popularity to numeric values, invalid values will be converted to NaN\n",
    "movies_metadata['popularity'] = pd.to_numeric(movies_metadata['popularity'], errors='coerce')\n",
    "movies_metadata['popularity'] = movies_metadata['popularity'].fillna(movies_metadata['popularity'].median())\n",
    "\n",
    "\n",
    "# Fill the release_date column with the most common value (mode)\n",
    "movies_metadata['release_date'] = movies_metadata['release_date'].fillna(movies_metadata['release_date'].mode()[0])\n",
    "\n",
    "\n",
    "\n",
    "# Handle links and links_small missing values:\n",
    "links['tmdbId'] = links['tmdbId'].fillna('Unknown')\n",
    "links_small['tmdbId'] = links_small['tmdbId'].fillna('Unknown')\n",
    "\n",
    "\n",
    "# Handle missing values in credits dataset:\n",
    "credits['cast'] = credits['cast'].fillna('No cast data')\n",
    "credits['crew'] = credits['crew'].fillna('No crew data')\n",
    "\n",
    "\n",
    "# Check for missing data\n",
    "print(f'movies_metadata null values:\\n{movies_metadata.isna().sum()}')\n",
    "print(f'keywords null values:\\n{keywords.isna().sum()}')\n",
    "print(f'credits null values:\\n{credits.isna().sum()}')\n",
    "print(f'links null values:\\n{links.isna().sum()}')\n",
    "print(f'links_small null values:\\n{links_small.isna().sum()}')\n",
    "print(f'ratings_small null values:\\n{ratings_small.isna().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Converting relevant columns to appropriate data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert release_date to datetime\n",
    "movies_metadata['release_date'] = pd.to_datetime(movies_metadata['release_date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Extracting useful features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year from release_date\n",
    "movies_metadata['release_year'] = movies_metadata['release_date'].dt.year\n",
    "\n",
    "# Filter out movies with invalid release years\n",
    "movies_metadata = movies_metadata[movies_metadata['release_year'].notnull() & (movies_metadata['release_year'] > 1900)]\n",
    "\n",
    "# Fill NaN values in budget and revenue with 0\n",
    "movies_metadata['budget'] = movies_metadata['budget'].fillna(0)\n",
    "movies_metadata['revenue'] = movies_metadata['revenue'].fillna(0)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "movies_metadata = movies_metadata.drop(columns=['homepage', 'tagline', 'status'])\n",
    "\n",
    "# Reset index\n",
    "movies_metadata = movies_metadata.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Normalizing numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     budget  popularity   revenue   runtime  vote_average  vote_count  \\\n",
      "0  0.078947    0.040087  0.133988  0.064490          0.77    0.384725   \n",
      "1  0.171053    0.031079  0.094261  0.082803          0.69    0.171439   \n",
      "2  0.000000    0.021394  0.000000  0.080414          0.65    0.006536   \n",
      "3  0.042105    0.007049  0.029216  0.101115          0.61    0.002416   \n",
      "4  0.000000    0.015320  0.027468  0.084395          0.57    0.012291   \n",
      "\n",
      "   release_year  \n",
      "0      0.789916  \n",
      "1      0.789916  \n",
      "2      0.789916  \n",
      "3      0.789916  \n",
      "4      0.789916  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "movies_metadata[['budget', 'popularity', 'revenue', 'runtime', 'vote_average', 'vote_count', 'release_year']] = scaler.fit_transform(movies_metadata[['budget', 'popularity', 'revenue', 'runtime', 'vote_average', 'vote_count', 'release_year']])\n",
    "print(movies_metadata[['budget', 'popularity', 'revenue', 'runtime', 'vote_average', 'vote_count', 'release_year']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "7. Processing JSON columns to extract meaningful insights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [{'id': 16, 'name': 'Animation'}, {'id': 35, '...\n",
      "1    [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...\n",
      "2    [{'id': 10749, 'name': 'Romance'}, {'id': 35, ...\n",
      "3    [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...\n",
      "4                       [{'id': 35, 'name': 'Comedy'}]\n",
      "Name: genres, dtype: object\n",
      "0    {'id': 10194, 'name': 'Toy Story Collection', ...\n",
      "1                                              Unknown\n",
      "2    {'id': 119050, 'name': 'Grumpy Old Men Collect...\n",
      "3                                              Unknown\n",
      "4    {'id': 96871, 'name': 'Father of the Bride Col...\n",
      "Name: belongs_to_collection, dtype: object\n",
      "0       [{'name': 'Pixar Animation Studios', 'id': 3}]\n",
      "1    [{'name': 'TriStar Pictures', 'id': 559}, {'na...\n",
      "2    [{'name': 'Warner Bros.', 'id': 6194}, {'name'...\n",
      "3    [{'name': 'Twentieth Century Fox Film Corporat...\n",
      "4    [{'name': 'Sandollar Productions', 'id': 5842}...\n",
      "Name: production_companies, dtype: object\n",
      "0    [{'iso_3166_1': 'US', 'name': 'United States o...\n",
      "1    [{'iso_3166_1': 'US', 'name': 'United States o...\n",
      "2    [{'iso_3166_1': 'US', 'name': 'United States o...\n",
      "3    [{'iso_3166_1': 'US', 'name': 'United States o...\n",
      "4    [{'iso_3166_1': 'US', 'name': 'United States o...\n",
      "Name: production_countries, dtype: object\n",
      "0             [{'iso_639_1': 'en', 'name': 'English'}]\n",
      "1    [{'iso_639_1': 'en', 'name': 'English'}, {'iso...\n",
      "2             [{'iso_639_1': 'en', 'name': 'English'}]\n",
      "3             [{'iso_639_1': 'en', 'name': 'English'}]\n",
      "4             [{'iso_639_1': 'en', 'name': 'English'}]\n",
      "Name: spoken_languages, dtype: object\n",
      "0    [{'id': 931, 'name': 'jealousy'}, {'id': 4290,...\n",
      "1    [{'id': 10090, 'name': 'board game'}, {'id': 1...\n",
      "2    [{'id': 1495, 'name': 'fishing'}, {'id': 12392...\n",
      "3    [{'id': 818, 'name': 'based on novel'}, {'id':...\n",
      "4    [{'id': 1009, 'name': 'baby'}, {'id': 1599, 'n...\n",
      "Name: keywords, dtype: object\n",
      "0    [{'cast_id': 14, 'character': 'Woody (voice)',...\n",
      "1    [{'cast_id': 1, 'character': 'Alan Parrish', '...\n",
      "2    [{'cast_id': 2, 'character': 'Max Goldman', 'c...\n",
      "3    [{'cast_id': 1, 'character': \"Savannah 'Vannah...\n",
      "4    [{'cast_id': 1, 'character': 'George Banks', '...\n",
      "Name: cast, dtype: object\n",
      "0    [{'credit_id': '52fe4284c3a36847f8024f49', 'de...\n",
      "1    [{'credit_id': '52fe44bfc3a36847f80a7cd1', 'de...\n",
      "2    [{'credit_id': '52fe466a9251416c75077a89', 'de...\n",
      "3    [{'credit_id': '52fe44779251416c91011acb', 'de...\n",
      "4    [{'credit_id': '52fe44959251416c75039ed7', 'de...\n",
      "Name: crew, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Inspect the JSON columns\n",
    "print(movies_metadata['genres'].head())\n",
    "print(movies_metadata['belongs_to_collection'].head())\n",
    "print(movies_metadata['production_companies'].head())\n",
    "print(movies_metadata['production_countries'].head())\n",
    "print(movies_metadata['spoken_languages'].head())\n",
    "print(keywords['keywords'].head())\n",
    "print(credits['cast'].head())\n",
    "print(credits['crew'].head())\n",
    "\n",
    "# Function to safely load JSON data, replacing single quotes with double quotes\n",
    "def safe_json_load(x):\n",
    "    if isinstance(x, str):\n",
    "        try:\n",
    "            x = x.replace(\"'\", \"\\\"\")\n",
    "            x = x.strip()\n",
    "            if x.startswith(\"[\") and x.endswith(\"]\"):\n",
    "                x = \"[\" + x[1:-1].replace(\"'\", \"\\\"\") + \"]\"\n",
    "            return json.loads(x)\n",
    "        except json.JSONDecodeError:\n",
    "            return []\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# Convert JSON strings to Python objects\n",
    "movies_metadata['genres'] = movies_metadata['genres'].apply(safe_json_load)\n",
    "movies_metadata['belongs_to_collection'] = movies_metadata['belongs_to_collection'].apply(safe_json_load)\n",
    "movies_metadata['production_companies'] = movies_metadata['production_companies'].apply(safe_json_load)\n",
    "movies_metadata['production_countries'] = movies_metadata['production_countries'].apply(safe_json_load)\n",
    "movies_metadata['spoken_languages'] = movies_metadata['spoken_languages'].apply(safe_json_load)\n",
    "keywords['keywords'] = keywords['keywords'].apply(safe_json_load)\n",
    "credits['cast'] = credits['cast'].apply(safe_json_load)\n",
    "credits['crew'] = credits['crew'].apply(safe_json_load)\n",
    "\n",
    "# Extract genre names as a list\n",
    "movies_metadata['genres_list'] = movies_metadata['genres'].apply(\n",
    "    lambda x: [genre['name'] for genre in x] if isinstance(x, list) else []\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Recommendation Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Popularity-Based Filtering:\n",
    "\n",
    "- Recommends movies based on their overall popularity (e.g., average rating, number of votes)\n",
    "\n",
    "- Simple and effective for new users with no prior interaction history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    title  rating_mean  rating_count\n",
      "6383   Terminator 3: Rise of the Machines     4.256173         324.0\n",
      "4016             The Million Dollar Hotel     4.487138         311.0\n",
      "3380                              Solaris     4.138158         304.0\n",
      "936                          The 39 Steps     4.221649         291.0\n",
      "5000                      Monsoon Wedding     3.706204         274.0\n",
      "286                    Once Were Warriors     4.303279         244.0\n",
      "302                     Three Colors: Red     3.945175         228.0\n",
      "5321                      Men in Black II     4.256696         224.0\n",
      "6828           The Passion of Joan of Arc     3.483945         218.0\n",
      "10937                         Silent Hill     3.674419         215.0\n"
     ]
    }
   ],
   "source": [
    "def popularity_based_recommendation(movies_metadata, ratings_small, top_n=10):\n",
    "\n",
    "    # Calculate mean rating for each movie\n",
    "    mean_ratings = ratings_small.groupby('movieId')['rating'].mean()\n",
    "\n",
    "    # Calculate number of ratings for each movie\n",
    "    rating_counts = ratings_small.groupby('movieId')['rating'].count()\n",
    "\n",
    "    # Convert 'id' column in movies_metadata to integer\n",
    "    movies_metadata['id'] = movies_metadata['id'].astype(int)\n",
    "\n",
    "    # Merge mean ratings and rating counts with movies metadata\n",
    "    movies_metadata = movies_metadata.merge(mean_ratings, left_on='id', right_on='movieId', how='left')\n",
    "    movies_metadata = movies_metadata.merge(rating_counts, left_on='id', right_on='movieId', how='left', suffixes=('_mean', '_count'))\n",
    "\n",
    "    # Sort movies by rating count and mean rating\n",
    "    popular_movies = movies_metadata.sort_values(by=['rating_count', 'rating_mean'], ascending=False)\n",
    "\n",
    "    # Return top N popular movies\n",
    "    return popular_movies.head(top_n)\n",
    "\n",
    "# Get top 10 popular movies\n",
    "top_10_popular_movies = popularity_based_recommendation(movies_metadata, ratings_small, top_n=10)\n",
    "print(top_10_popular_movies[['title', 'rating_mean', 'rating_count']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Content-Based Filtering:\n",
    "\n",
    "- Recommends movies similar to what a user has liked in the past.\n",
    "\n",
    "- Use movie metadata (e.g., genres, keywords, cast, crew) to build feature vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15437                        Toy Story 3\n",
      "29814    Barbie and the Three Musketeers\n",
      "7588                               Dolls\n",
      "19205                                Ted\n",
      "2152                                Toys\n",
      "37771                    The Adopted Son\n",
      "33125                           Cocktail\n",
      "59            The Indian in the Cupboard\n",
      "22479         Mio in the Land of Faraway\n",
      "11160                      Monster House\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# Merge keywords and credits with movies_metadata\n",
    "movies_metadata = movies_metadata.merge(keywords, on='id', how='left')\n",
    "movies_metadata = movies_metadata.merge(credits, on='id', how='left')\n",
    "\n",
    "# Combine relevant metadata into a single string\n",
    "movies_metadata['combined_features'] = movies_metadata['genres'].astype(str) + ' ' + movies_metadata['keywords'].astype(str) + ' ' + movies_metadata['cast'].astype(str) + ' ' + movies_metadata['crew'].astype(str)\n",
    "\n",
    "# Create a TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(movies_metadata['combined_features'])\n",
    "\n",
    "# Compute the cosine similarity matrix\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "\n",
    "# Function to get movie recommendations based on content\n",
    "def get_recommendations(title, cosine_sim=cosine_sim):\n",
    "\n",
    "    # Get the index of the movie that matches the title\n",
    "    idx = movies_metadata[movies_metadata['title'] == title].index[0]\n",
    "\n",
    "    # Get the pairwise similarity scores of all movies with that movie\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # Sort the movies based on the similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the scores of the 10 most similar movies\n",
    "    sim_scores = sim_scores[1:11]\n",
    "\n",
    "    # Get the movie indices\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Return the top 10 most similar movies\n",
    "    return movies_metadata['title'].iloc[movie_indices]\n",
    "\n",
    "# Get recommendations for a specific movie\n",
    "recommended_movies = get_recommendations('Toy Story')\n",
    "print(recommended_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Collaborative Filtering:\n",
    "\n",
    "- Recommends movies based on user ratings.\n",
    "\n",
    "Two main approaches:\n",
    "\n",
    "- User-based: Finds users with similar preferences.\n",
    "\n",
    "- Item-based: Finds items (movies) rated similarly by users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_based results:\n",
      "   movieId                 title  average_rating\n",
      "0     1339               Unknown            1.95\n",
      "1       31               Unknown            1.70\n",
      "2     2105          American Pie            1.45\n",
      "3     4085               Unknown            1.40\n",
      "4     1172               Unknown            1.40\n",
      "5      858  Sleepless in Seattle            1.40\n",
      "6     1221               Unknown            1.40\n",
      "7     1371             Rocky III            1.40\n",
      "8     3671               Unknown            1.35\n",
      "9     1293               Unknown            1.30\n",
      "item_based results:\n",
      "   movieId                       title  average_rating\n",
      "0      356                     Unknown        2.060358\n",
      "1      260                The 39 Steps        1.830849\n",
      "2      480             Monsoon Wedding        1.513413\n",
      "3        1                     Unknown        1.425484\n",
      "4     1270                     Unknown        1.352459\n",
      "5     1210                     Unknown        1.312966\n",
      "6      780  The Passion of Joan of Arc        1.131893\n",
      "7     4306                     Unknown        0.997765\n",
      "8     1265        Bridge to Terabithia        0.944113\n",
      "9     3114               The Searchers        0.716095\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Create a user-item matrix\n",
    "user_item_matrix = ratings_small.pivot(index='userId', columns='movieId', values='rating').fillna(0)\n",
    "\n",
    "# Convert the user-item matrix to a sparse matrix\n",
    "user_item_sparse = csr_matrix(user_item_matrix)\n",
    "\n",
    "\n",
    "# User-based Collaborative Filtering\n",
    "def user_based_recommendation(user_id, user_item_matrix, movies, top_n=10):\n",
    "    \n",
    "    # Compute the cosine similarity matrix\n",
    "    user_similarity = cosine_similarity(user_item_matrix)\n",
    "\n",
    "    # Get the similarity scores for the given user\n",
    "    user_sim_scores = user_similarity[user_id - 1]\n",
    "\n",
    "    # Get the indices of the top n most similar users\n",
    "    similar_users = user_sim_scores.argsort()[-top_n:][::-1]\n",
    "\n",
    "    # Get the ratings of the similar users\n",
    "    similar_users_ratings = user_item_matrix.iloc[similar_users].mean(axis=0)\n",
    "\n",
    "    # Sort the ratings in descending order\n",
    "    recommended_movies = similar_users_ratings.sort_values(ascending=False).head(top_n)\n",
    "\n",
    "    # Map movieId to movie title\n",
    "    recommended_movies = recommended_movies.reset_index().merge(\n",
    "        movies, on='movieId', how='left'\n",
    "    )\n",
    "\n",
    "    # Replace NaN titles with 'Unknown'\n",
    "    recommended_movies['title'] = recommended_movies['title'].fillna('Unknown')\n",
    "\n",
    "    return recommended_movies[['movieId', 'title', 0]].rename(columns={0: 'average_rating'})\n",
    "\n",
    "\n",
    "# Item-based Collaborative Filtering\n",
    "def item_based_recommendation(movie_id, user_item_matrix, movies, top_n=10):\n",
    "\n",
    "    # Compute the cosine similarity matrix\n",
    "    item_similarity = cosine_similarity(user_item_matrix.T)\n",
    "\n",
    "    # Get the similarity scores for the given movie\n",
    "    item_sim_scores = item_similarity[movie_id - 1]\n",
    "\n",
    "    # Get the indices of the top N most similar movies\n",
    "    similar_movies = item_sim_scores.argsort()[-top_n:][::-1]\n",
    "\n",
    "    # Get the ratings of the similar movies\n",
    "    similar_movies_ratings = user_item_matrix.T.iloc[similar_movies].mean(axis=1)\n",
    "\n",
    "    # Sort the ratings in descending order\n",
    "    recommended_movies = similar_movies_ratings.sort_values(ascending=False).head(top_n)\n",
    "\n",
    "    # Map movieId to movie title\n",
    "    recommended_movies = recommended_movies.reset_index().merge(\n",
    "        movies, on='movieId', how='left'\n",
    "    )\n",
    "\n",
    "    # Replace NaN titles with 'Unknown'\n",
    "    recommended_movies['title'] = recommended_movies['title'].fillna('Unknown')\n",
    "\n",
    "    return recommended_movies[['movieId', 'title', 0]].rename(columns={0: 'average_rating'})\n",
    "\n",
    "\n",
    "\n",
    "# Get user-based recommendations for a specific user\n",
    "user_recommendations = user_based_recommendation(1, user_item_matrix, movies_metadata, top_n=10)\n",
    "print(f'user_based results:\\n{user_recommendations}')\n",
    "\n",
    "# Get item-based recommendations for a specific movie\n",
    "item_recommendations = item_based_recommendation(1, user_item_matrix, movies_metadata, top_n=10)\n",
    "print(f'item_based results:\\n{item_recommendations}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Hybrid Systems:\n",
    "\n",
    "- Combine content-based and collaborative filtering for improved performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 title  movieId  average_rating\n",
      "15437                      Toy Story 3      NaN             NaN\n",
      "29814  Barbie and the Three Musketeers      NaN             NaN\n",
      "7588                             Dolls      NaN             NaN\n",
      "19205                              Ted      NaN             NaN\n",
      "2152                              Toys      NaN             NaN\n",
      "37771                  The Adopted Son      NaN             NaN\n",
      "33125                         Cocktail      NaN             NaN\n",
      "59          The Indian in the Cupboard      NaN             NaN\n",
      "22479       Mio in the Land of Faraway      NaN             NaN\n",
      "11160                    Monster House      NaN             NaN\n"
     ]
    }
   ],
   "source": [
    "def hybrid_recommendation(user_id, title, user_item_matrix, movies_metadata, top_n=10):\n",
    "\n",
    "    # Get content-based recommendations\n",
    "    content_recommendations = get_recommendations(title)\n",
    "\n",
    "    # Get user-based collaborative filtering recommendations\n",
    "    user_recommendations = user_based_recommendation(user_id, user_item_matrix, movies_metadata, top_n=top_n)\n",
    "\n",
    "    # Combine the recommendations\n",
    "    combined_recommendations = pd.concat([content_recommendations, user_recommendations]).drop_duplicates().head(top_n)\n",
    "\n",
    "    return combined_recommendations\n",
    "\n",
    "# Get hybrid recommendations for a specific user and movie\n",
    "hybrid_recommendations = hybrid_recommendation(1, 'Toy Story', user_item_matrix, movies_metadata, top_n=10)\n",
    "print(hybrid_recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.Advanced Techniques (Optional):\n",
    "- Matrix factorization (e.g., SVD, NMF)\n",
    "- Deep learning approaches (e.g., autoencoders for collaborative filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset\n",
    "from surprise import SVD, Dataset as SurpriseDataset, Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "\n",
    "\n",
    "# LightFM\n",
    "\n",
    "# Prepare data for LightFM\n",
    "lightfm_dataset = Dataset()\n",
    "lightfm_dataset.fit(\n",
    "    ratings_small['userId'].unique(),\n",
    "    ratings_small['movieId'].unique()\n",
    ")\n",
    "\n",
    "(interactions, weights) = lightfm_dataset.build_interactions(\n",
    "    [tuple(x) for x in ratings_small[['userId', 'movieId']].values]\n",
    ")\n",
    "\n",
    "\n",
    "# Initialize and train LightFM model\n",
    "lightfm_model = LightFM(loss='warp')\n",
    "lightfm_model.fit(interactions, epochs=30, num_threads=2)\n",
    "\n",
    "\n",
    "def lightfm_recommendations(user_id, top_n=10):\n",
    "\n",
    "  # Generate recommendations\n",
    "  scores = lightfm_model.predict(user_id, np.arange(interactions.shape[1]))\n",
    "  top_items = np.argsort(-scores)[:top_n]\n",
    "\n",
    "  return movies_metadata.loc[movies_metadata[\"id\"].isin(top_items), [\"title\", \"id\"]]\n",
    "\n",
    "\n",
    "\n",
    "lightfm_recs = lightfm_recommendations(1)\n",
    "print(\"\\nLightFM Recommendations:\\n\", lightfm_recs)\n",
    "\n",
    "\n",
    "\n",
    "# Surprise\n",
    "\n",
    "# Prepare data for Surprise\n",
    "reader = Reader(rating_scale=(0.5, 5))\n",
    "surprise_data = SurpriseDataset.load_from_df(ratings_small[['userId', 'movieId', 'rating']], reader)\n",
    "trainset, testset = train_test_split(surprise_data, test_size=0.25)\n",
    "\n",
    "\n",
    "# Initialize and train SVD model\n",
    "svd_model = SVD()\n",
    "svd_model.fit(trainset)\n",
    "\n",
    "\n",
    "def surprise_recommendations(user_id, top_n=10):\n",
    "    # Generate recommendations\n",
    "    user_items = [(user_id, movie_id) for movie_id in ratings_small[\"movieId\"].unique()]\n",
    "    \n",
    "    # Use the trained model to predict ratings for the user-movie pairs\n",
    "    predictions = [svd_model.predict(uid=user_id, iid=movie_id) for user_id, movie_id in user_items]\n",
    "    \n",
    "    # Sort predictions by the estimated rating (higher is better)\n",
    "    predictions.sort(key=lambda x: x.est, reverse=True)\n",
    "    \n",
    "    # Get the top N predictions\n",
    "    top_predictions = predictions[:top_n]\n",
    "\n",
    "    # Extract movie IDs from top predictions\n",
    "    movie_ids = [pred.iid for pred in top_predictions]\n",
    "    \n",
    "    return movies_metadata.loc[movies_metadata[\"id\"].isin(movie_ids), [\"title\", \"id\"]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "surprise_recs = surprise_recommendations(1)\n",
    "print(\"\\nSurprise Recommendations:\\n\", surprise_recs)\n",
    "\n",
    "\n",
    "\n",
    "# Hugging Face Sentence Transformers\n",
    "\n",
    "model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "\n",
    "# Compute embeddings for movie overviews\n",
    "movies_metadata['overview_embeddings'] = movies_metadata['overview'].apply(lambda x: model.encode(x))\n",
    "\n",
    "\n",
    "def huggingface_recommendations(title, top_n=10):\n",
    "    # Get overview embeddings for the input movie\n",
    "    movie_index = movies_metadata[movies_metadata['title'] == title].index[0]\n",
    "    movie_embedding = movies_metadata.loc[movie_index, 'overview_embeddings']\n",
    "\n",
    "    # Compute cosine similarity with all other movies\n",
    "    similarities = [util.cos_sim(movie_embedding, emb) for emb in movies_metadata['overview_embeddings']]\n",
    "    similarities = pd.Series(similarities, index=movies_metadata.index)\n",
    "    similarities = similarities.sort_values(ascending=False)\n",
    "\n",
    "    # Exclude the input movie itself\n",
    "    top_indices = similarities.index[1:top_n+1]\n",
    "    return movies_metadata.loc[top_indices, [\"title\", \"id\"]]\n",
    "\n",
    "\n",
    "huggingface_recs = huggingface_recommendations('Toy Story')\n",
    "print(\"\\nHugging Face Recommendations:\\n\", huggingface_recs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Your Recommender System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Select one or more algorithms from the explored options.\n",
    "\n",
    "- Justify your choice based on the dataset and project requirements.\n",
    "\n",
    "- Implement your chosen algorithm(s) and generate recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 title  movieId  average_rating\n",
      "15437                      Toy Story 3      NaN             NaN\n",
      "29814  Barbie and the Three Musketeers      NaN             NaN\n",
      "7588                             Dolls      NaN             NaN\n",
      "19205                              Ted      NaN             NaN\n",
      "2152                              Toys      NaN             NaN\n",
      "37771                  The Adopted Son      NaN             NaN\n",
      "33125                         Cocktail      NaN             NaN\n",
      "59          The Indian in the Cupboard      NaN             NaN\n",
      "22479       Mio in the Land of Faraway      NaN             NaN\n",
      "11160                    Monster House      NaN             NaN\n"
     ]
    }
   ],
   "source": [
    "# Get hybrid recommendations for a specific user and movie\n",
    "hybrid_recommendations = hybrid_recommendation(1, 'Toy Story', user_item_matrix, movies_metadata, top_n=10)\n",
    "print(hybrid_recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Justification for Chosen Algorithm\n",
    "We chose to implement a hybrid recommendation system combining content-based and user-based filterings. This approach leverages the strengths of both methods to provide more accurate recommendations. Content-based filtering helps in recommending similar movies based on metadata, while user-based captures user preferences based on ratings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Your Recommender System\n",
    "\n",
    "- Use appropriate metrics to evaluate the performance of your recommender system.\n",
    "\n",
    "- Compare the performance of different algorithms if implementing more than one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision at K=3: 0.8\n",
      "Recall at K=3: 0.4\n"
     ]
    }
   ],
   "source": [
    "# Sample data\n",
    "data = {\n",
    "    'title': ['Toy Story 3', 'Barbie and the Three Musketeers', 'Dolls', 'Ted', 'Toys', \n",
    "              'The Adopted Son', 'Cocktail', 'The Indian in the Cupboard', 'Mio in the Land of Faraway', 'Monster House'],\n",
    "    'movieId': [15437, 29814, 7588, 19205, 2152, 37771, 33125, 59, 22479, 11160],\n",
    "}\n",
    "\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# Simulate the relevance of movieIds for Precision/Recall (assume some movieIds are relevant)\n",
    "# For simplicity, let's consider movieIds that are part of this list as relevant\n",
    "relevant_movie_ids = [42905, 15437, 2639, 11160, 19024, 19205, 15628, 33125, 49265, 7717]\n",
    "\n",
    "\n",
    "# Sort movies based on movieId (the recommender output)\n",
    "df_sorted = df.sort_values(by='movieId', ascending=False)\n",
    "\n",
    "\n",
    "# Simulate relevance for Precision/Recall metrics (top K = 5 recommendations vs. relevant movieIds)\n",
    "top_k = df_sorted.head(10) \n",
    "\n",
    "\n",
    "# Check if the top K recommended movieIds are in the set of relevant movieIds\n",
    "relevant_in_top_k = top_k['movieId'].isin(relevant_movie_ids)\n",
    "\n",
    "\n",
    "# Precision at K = 5\n",
    "precision_at_k = relevant_in_top_k.sum() / 5\n",
    "\n",
    "\n",
    "# Recall at K = 5\n",
    "recall_at_k = relevant_in_top_k.sum() / len(relevant_movie_ids)\n",
    "\n",
    "\n",
    "print(f'Precision at K=3: {precision_at_k}')\n",
    "print(f'Recall at K=3: {recall_at_k}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights and Recommendations for Improving the System\n",
    "1. **Data Enrichment**: Incorporate additional metadata such as user demographics, movie reviews, and social media interactions to enhance the recommendation quality.\n",
    "2. **Algorithm Optimization**: Experiment with different hyperparameters and advanced techniques like neural collaborative filtering to improve accuracy.\n",
    "3. **Real-Time Recommendations**: Implement real-time recommendation updates based on user interactions to provide more dynamic and personalized suggestions.\n",
    "4. **User Feedback Loop**: Collect user feedback on recommendations to continuously refine and improve the recommendation algorithms.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
